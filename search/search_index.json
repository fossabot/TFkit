{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Getting started \u00b6 Installing via pip \u00b6 pip install tfkit You can use tfkit for model training and evaluation with tfkit-train and tfkit-eval . Running TFKit on the task you wanted \u00b6 First step - prepare your dataset \u00b6 The key to combine different task together is to make different task with same data format. notice All data will be in csv format - tfkit will use csv for all task, normally it will have two columns, first columns is the input of models, the second column is the output of models. Plane text with no tokenization - there is no need to tokenize text before training, or do re-calculating for tokenization, tfkit will handle it for you. No header is needed. For example, a sentiment classification dataset will be like: how dare you,negative Hint For the detail and example format on different, you can check here Hint nlprep is a tool for data split/preprocessing/argumentation, it can help you to create ready to train data for tfkit, check here Second step - model training \u00b6 Using tfkit-train for model training, you can use Before training a model, there is something you need to clarify: --model what is your model to handle this task? check here to the detail of models. --config what pretrained model you want to use\uff1f you can go https://huggingface.co/models to search for available pretrained models. --train and --test training and testing dataset path, which is in csv format. --savedir model saving directory, default will be in '/checkpoints' folder you can leave the rest to the default config, or use tfkit-train -h to more configuration. An example about training a sentiment classifier: tfkit-train \\ --model clas \\ --config xlm-roberta-base \\ --train training_data.csv \\ --test testing_data.csv \\ --lr 4e-5 \\ --maxlen 384 \\ --epoch 10 \\ --savedir roberta_sentiment_classificer Third step - model eval \u00b6 Using tfkit-eval for model evaluation. - --model saved model's path. - --metric the evaluation metric eg: emf1, nlg(BLEU/ROUGE), clas(confusion matrix). - --valid validation data, also in csv format. - --panel a input panel for model specific parameter. for more configuration detail, you may use tfkit-eval -h . After evaluate, It will print evaluate result in your console, and also generate three report for debugging. - *_score.csv overall score, it is the copy of the console result. - *each_data_score.csv score on each data, 3 column predicted,targets,score , ranked from the lowest to the highest. - *predicted.csv csv file include 3 column input,predicted,targets . Hint nlp2go is a tool for demonstration, with CLI and Restful interface. check here Example \u00b6 Use distilbert to train NER Model \u00b6 nlprep --dataset tag_clner --outdir ./clner_row --util s2t tfkit-train --batch 10 --epoch 3 --lr 5e-6 --train ./clner_row/train --test ./clner_row/test --maxlen 512 --model tag --config distilbert-base-multilingual-cased nlp2go --model ./checkpoints/3.pt --cli Use Albert to train DRCD Model Model \u00b6 nlprep --dataset qa_zh --outdir ./zhqa/ tfkit-train --maxlen 512 --savedir ./drcd_qa_model/ --train ./zhqa/drcd-train --test ./zhqa/drcd-test --model qa --config voidful/albert_chinese_small --cache nlp2go --model ./drcd_qa_model/3.pt --cli Use Albert to train both DRCD Model and NER Model \u00b6 nlprep --dataset tag_clner --outdir ./clner_row --util s2t nlprep --dataset qa_zh --outdir ./zhqa/ tfkit-train --maxlen 300 --savedir ./mt-qaner --train ./clner_row/train ./zhqa/drcd-train --test ./clner_row/test ./zhqa/drcd-test --model tag qa --config voidful/albert_chinese_small nlp2go --model ./mt-qaner/3.pt --cli You can also try tfkit in Google Colab: Contributing \u00b6 Thanks for your interest.There are many ways to contribute to this project. Get started here . License \u00b6 License Icons reference \u00b6 Icons modify from Freepik from www.flaticon.com Icons modify from Nikita Golubev from www.flaticon.com","title":"Home"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#installing-via-pip","text":"pip install tfkit You can use tfkit for model training and evaluation with tfkit-train and tfkit-eval .","title":"Installing via pip"},{"location":"#running-tfkit-on-the-task-you-wanted","text":"","title":"Running TFKit on the task you wanted"},{"location":"#first-step-prepare-your-dataset","text":"The key to combine different task together is to make different task with same data format. notice All data will be in csv format - tfkit will use csv for all task, normally it will have two columns, first columns is the input of models, the second column is the output of models. Plane text with no tokenization - there is no need to tokenize text before training, or do re-calculating for tokenization, tfkit will handle it for you. No header is needed. For example, a sentiment classification dataset will be like: how dare you,negative Hint For the detail and example format on different, you can check here Hint nlprep is a tool for data split/preprocessing/argumentation, it can help you to create ready to train data for tfkit, check here","title":"First step - prepare your dataset"},{"location":"#second-step-model-training","text":"Using tfkit-train for model training, you can use Before training a model, there is something you need to clarify: --model what is your model to handle this task? check here to the detail of models. --config what pretrained model you want to use\uff1f you can go https://huggingface.co/models to search for available pretrained models. --train and --test training and testing dataset path, which is in csv format. --savedir model saving directory, default will be in '/checkpoints' folder you can leave the rest to the default config, or use tfkit-train -h to more configuration. An example about training a sentiment classifier: tfkit-train \\ --model clas \\ --config xlm-roberta-base \\ --train training_data.csv \\ --test testing_data.csv \\ --lr 4e-5 \\ --maxlen 384 \\ --epoch 10 \\ --savedir roberta_sentiment_classificer","title":"Second step - model training"},{"location":"#third-step-model-eval","text":"Using tfkit-eval for model evaluation. - --model saved model's path. - --metric the evaluation metric eg: emf1, nlg(BLEU/ROUGE), clas(confusion matrix). - --valid validation data, also in csv format. - --panel a input panel for model specific parameter. for more configuration detail, you may use tfkit-eval -h . After evaluate, It will print evaluate result in your console, and also generate three report for debugging. - *_score.csv overall score, it is the copy of the console result. - *each_data_score.csv score on each data, 3 column predicted,targets,score , ranked from the lowest to the highest. - *predicted.csv csv file include 3 column input,predicted,targets . Hint nlp2go is a tool for demonstration, with CLI and Restful interface. check here","title":"Third step - model eval"},{"location":"#example","text":"","title":"Example"},{"location":"#use-distilbert-to-train-ner-model","text":"nlprep --dataset tag_clner --outdir ./clner_row --util s2t tfkit-train --batch 10 --epoch 3 --lr 5e-6 --train ./clner_row/train --test ./clner_row/test --maxlen 512 --model tag --config distilbert-base-multilingual-cased nlp2go --model ./checkpoints/3.pt --cli","title":"Use distilbert to train NER Model"},{"location":"#use-albert-to-train-drcd-model-model","text":"nlprep --dataset qa_zh --outdir ./zhqa/ tfkit-train --maxlen 512 --savedir ./drcd_qa_model/ --train ./zhqa/drcd-train --test ./zhqa/drcd-test --model qa --config voidful/albert_chinese_small --cache nlp2go --model ./drcd_qa_model/3.pt --cli","title":"Use Albert to train DRCD Model Model"},{"location":"#use-albert-to-train-both-drcd-model-and-ner-model","text":"nlprep --dataset tag_clner --outdir ./clner_row --util s2t nlprep --dataset qa_zh --outdir ./zhqa/ tfkit-train --maxlen 300 --savedir ./mt-qaner --train ./clner_row/train ./zhqa/drcd-train --test ./clner_row/test ./zhqa/drcd-test --model tag qa --config voidful/albert_chinese_small nlp2go --model ./mt-qaner/3.pt --cli You can also try tfkit in Google Colab:","title":"Use Albert to train both DRCD Model and NER Model"},{"location":"#contributing","text":"Thanks for your interest.There are many ways to contribute to this project. Get started here .","title":"Contributing"},{"location":"#license","text":"License","title":"License"},{"location":"#icons-reference","text":"Icons modify from Freepik from www.flaticon.com Icons modify from Nikita Golubev from www.flaticon.com","title":"Icons reference"},{"location":"benchmark/","text":"DRCD \u00b6 Test \u00b6 model EM F1 albert-small 74.45% 86.08% electra-small 76.64% 87.49% albert-base 80.17% 89.87% Dev \u00b6 model EM F1 albert-small 73.70% 85.33% electra-small 77.61% 87.33% albert-base 80.52% 89.92%","title":"Benchmark"},{"location":"benchmark/#drcd","text":"","title":"DRCD"},{"location":"benchmark/#test","text":"model EM F1 albert-small 74.45% 86.08% electra-small 76.64% 87.49% albert-base 80.17% 89.87%","title":"Test"},{"location":"benchmark/#dev","text":"model EM F1 albert-small 73.70% 85.33% electra-small 77.61% 87.33% albert-base 80.52% 89.92%","title":"Dev"},{"location":"installation/","text":"Installation \u00b6 tfkit is tested on Python 3.6+, and PyTorch 1.1.0+. Installing via pip \u00b6 pip install tfkit Installing via source \u00b6 git clone https://github.com/voidful/tfkit.git python setup.py install # or pip install . Running tfkit \u00b6 Model you've installed tfkit, you can run with pip installed version: \u00b6 tfkit-train tfkit-eval tfkit-dump local version: \u00b6 python -m tfkit.train python -m tfkit.eval python -m tfkit.dump","title":"Installation"},{"location":"installation/#installation","text":"tfkit is tested on Python 3.6+, and PyTorch 1.1.0+.","title":"Installation"},{"location":"installation/#installing-via-pip","text":"pip install tfkit","title":"Installing via pip"},{"location":"installation/#installing-via-source","text":"git clone https://github.com/voidful/tfkit.git python setup.py install # or pip install .","title":"Installing via source"},{"location":"installation/#running-tfkit","text":"Model you've installed tfkit, you can run with","title":"Running tfkit"},{"location":"installation/#pip-installed-version","text":"tfkit-train tfkit-eval tfkit-dump","title":"pip installed version:"},{"location":"installation/#local-version","text":"python -m tfkit.train python -m tfkit.eval python -m tfkit.dump","title":"local version:"},{"location":"models/","text":"Models Overview \u00b6 task available models text generation seq2seq clm onebyone once oncectc extractive question answering qa multiple choice question answering mcq sequence tagging tag tagcrf sentence classification clas mask language model clm Text Generation \u00b6 seq2seq \u00b6 encoder decoder models for text generation, eg: T5/BART clm \u00b6 causal language model, decoder only models for text generation, eg: GPT onebyone \u00b6 onebyone text generation, for mask lm generation. once \u00b6 once text generation oncectc \u00b6 once text generation with ctc loss Extractive Question Answering \u00b6 qa \u00b6 SQuAD like question answer Multiple Choice Question Answering \u00b6 mcq \u00b6 softmax from mask token in input Sequence Tagging \u00b6 tag \u00b6 token classification tagcrf \u00b6 token classification with crf layer Sentence Classification \u00b6 clas \u00b6 sentence classification using pooling head from transformer models. Mask Language Model \u00b6 mask \u00b6 mask token prediction, for self-supervised learning","title":"Models"},{"location":"models/#models-overview","text":"task available models text generation seq2seq clm onebyone once oncectc extractive question answering qa multiple choice question answering mcq sequence tagging tag tagcrf sentence classification clas mask language model clm","title":"Models Overview"},{"location":"models/#text-generation","text":"","title":"Text Generation"},{"location":"models/#seq2seq","text":"encoder decoder models for text generation, eg: T5/BART","title":"seq2seq"},{"location":"models/#clm","text":"causal language model, decoder only models for text generation, eg: GPT","title":"clm"},{"location":"models/#onebyone","text":"onebyone text generation, for mask lm generation.","title":"onebyone"},{"location":"models/#once","text":"once text generation","title":"once"},{"location":"models/#oncectc","text":"once text generation with ctc loss","title":"oncectc"},{"location":"models/#extractive-question-answering","text":"","title":"Extractive Question Answering"},{"location":"models/#qa","text":"SQuAD like question answer","title":"qa"},{"location":"models/#multiple-choice-question-answering","text":"","title":"Multiple Choice Question Answering"},{"location":"models/#mcq","text":"softmax from mask token in input","title":"mcq"},{"location":"models/#sequence-tagging","text":"","title":"Sequence Tagging"},{"location":"models/#tag","text":"token classification","title":"tag"},{"location":"models/#tagcrf","text":"token classification with crf layer","title":"tagcrf"},{"location":"models/#sentence-classification","text":"","title":"Sentence Classification"},{"location":"models/#clas","text":"sentence classification using pooling head from transformer models.","title":"clas"},{"location":"models/#mask-language-model","text":"","title":"Mask Language Model"},{"location":"models/#mask","text":"mask token prediction, for self-supervised learning","title":"mask"},{"location":"structure/","text":"Overview \u00b6 Flow Project directory: . \u251c\u2500 demo_data/ # Example data for training and evaluation \u251c\u2500 docs/ # Documents \u251c\u2500 tfkit/ \u2502 \u251c\u2500 model/ # all of the models, subdir name will be model name \u2502 \u2502 \u251c\u2500 model_name # - name will be dynamic import to tfkit-train \u2502 \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500 dataloader.py # - for data loading and preprocessing \u2502 \u2502 \u2502 \u2514\u2500 model.py # - model forward and prediction \u2502 \u2502 \u2514\u2500 __init__.py \u2502 \u251c\u2500 test/ # project unit test \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u251c\u2500 test_atrain.py # - test tfkit-train \u2502 \u2502 \u251c\u2500 test_dataloader.py # - test all model/*/dataloader.py \u2502 \u2502 \u251c\u2500 test_model.py # - test all model/*/model.py \u2502 \u2502 \u251c\u2500 test_package.py # - test package import \u2502 \u2502 \u251c\u2500 test_utility_dataset.py # - test utility/dataset.py \u2502 \u2502 \u251c\u2500 test_utility_eval_metric.py # - test utility/eval_metric.py \u2502 \u2502 \u251c\u2500 test_utility_logger.py # - test utility/logger.py \u2502 \u2502 \u251c\u2500 test_utility_loss.py # - test utility/loss.py \u2502 \u2502 \u251c\u2500 test_utility_model_loader.py # - test utility/model_loader.py \u2502 \u2502 \u251c\u2500 test_utility_tok.py # - test utility/predictor.py \u2502 \u2502 \u251c\u2500 test_zeval.py # - test tfkit-eval \u2502 \u2502 \u2514\u2500 test_zzdump.py # - test tfkit-dump \u2502 \u251c\u2500 utility/ # project utility \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u251c\u2500 dataset.py # - handle dataset loading \u2502 \u2502 \u251c\u2500 eval_metric.py # - handle evaluation metric calculation \u2502 \u2502 \u251c\u2500 logger.py # - handle logging and printing \u2502 \u2502 \u251c\u2500 loss.py # - custom loss function \u2502 \u2502 \u251c\u2500 model_loader.py # - handle model loading \u2502 \u2502 \u251c\u2500 predictor.py # - handle model prediction \u2502 \u2502 \u2514\u2500 tok.py # - handle tokenization \u2502 \u251c\u2500 __init__.py # package init \u2502 \u251c\u2500 dump.py # tfkit-dump handler \u2502 \u251c\u2500 eval.py # tfkit-eval handler \u2502 \u2514\u2500 train.py # tfkit-train handler \u251c\u2500 Dockerfile # recommend docker file \u251c\u2500 mkdocs.yml # document config \u251c\u2500 README.md # project readme \u251c\u2500 requirements.txt # package requirement \u2514\u2500 setup.py # package setup","title":"Structure"},{"location":"structure/#overview","text":"Flow Project directory: . \u251c\u2500 demo_data/ # Example data for training and evaluation \u251c\u2500 docs/ # Documents \u251c\u2500 tfkit/ \u2502 \u251c\u2500 model/ # all of the models, subdir name will be model name \u2502 \u2502 \u251c\u2500 model_name # - name will be dynamic import to tfkit-train \u2502 \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500 dataloader.py # - for data loading and preprocessing \u2502 \u2502 \u2502 \u2514\u2500 model.py # - model forward and prediction \u2502 \u2502 \u2514\u2500 __init__.py \u2502 \u251c\u2500 test/ # project unit test \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u251c\u2500 test_atrain.py # - test tfkit-train \u2502 \u2502 \u251c\u2500 test_dataloader.py # - test all model/*/dataloader.py \u2502 \u2502 \u251c\u2500 test_model.py # - test all model/*/model.py \u2502 \u2502 \u251c\u2500 test_package.py # - test package import \u2502 \u2502 \u251c\u2500 test_utility_dataset.py # - test utility/dataset.py \u2502 \u2502 \u251c\u2500 test_utility_eval_metric.py # - test utility/eval_metric.py \u2502 \u2502 \u251c\u2500 test_utility_logger.py # - test utility/logger.py \u2502 \u2502 \u251c\u2500 test_utility_loss.py # - test utility/loss.py \u2502 \u2502 \u251c\u2500 test_utility_model_loader.py # - test utility/model_loader.py \u2502 \u2502 \u251c\u2500 test_utility_tok.py # - test utility/predictor.py \u2502 \u2502 \u251c\u2500 test_zeval.py # - test tfkit-eval \u2502 \u2502 \u2514\u2500 test_zzdump.py # - test tfkit-dump \u2502 \u251c\u2500 utility/ # project utility \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u2502 \u251c\u2500 dataset.py # - handle dataset loading \u2502 \u2502 \u251c\u2500 eval_metric.py # - handle evaluation metric calculation \u2502 \u2502 \u251c\u2500 logger.py # - handle logging and printing \u2502 \u2502 \u251c\u2500 loss.py # - custom loss function \u2502 \u2502 \u251c\u2500 model_loader.py # - handle model loading \u2502 \u2502 \u251c\u2500 predictor.py # - handle model prediction \u2502 \u2502 \u2514\u2500 tok.py # - handle tokenization \u2502 \u251c\u2500 __init__.py # package init \u2502 \u251c\u2500 dump.py # tfkit-dump handler \u2502 \u251c\u2500 eval.py # tfkit-eval handler \u2502 \u2514\u2500 train.py # tfkit-train handler \u251c\u2500 Dockerfile # recommend docker file \u251c\u2500 mkdocs.yml # document config \u251c\u2500 README.md # project readme \u251c\u2500 requirements.txt # package requirement \u2514\u2500 setup.py # package setup","title":"Overview"},{"location":"tasks/","text":"Task format \u00b6 Classification \u00b6 Info multi-class classification: \u00b6 Format: input sentence,label Example: Calotropis procera (ushaar) keratitis.,Not-Related multi-label classification \u00b6 use /// to separate each label. Format: input sentence,label1///label2 Example : We report two cases of pseudoporphyria caused by naproxen and oxaprozin.,Related///METHODS Text Generation \u00b6 Info Format: input sentence, target sentence Example : Peter was a truck driver . He was running a little behind on schedule . Peter decided to run past the weigh station . He was stopped by a cop .,\"Peter ended up running late and getting a fine .\" Extractive Question Answering \u00b6 Info Format: input sentence with question, answer start position, answer end position Example : Beyonc\u00e9 announced a hiatus from her music ... <s> Who suggested the hiatus for Beyonc\u00e9?, 74,84 Multiple-Choice Question Answering \u00b6 Info Input passage should include all available, each choice must start with a mask token each choice must start with a mask token choice id will be start from 0 Format: input passage [MASK]choiceA [MASK]choiceB, 1 Example : \"I 'm sure many of you have seen Star Wars ... </s> What is the best title of the passage ? [MASK] What Is Human Cloning [MASK] How Does Human Cloning Happen [MASK] Human Cloning Is Wrong [MASK] Discussion On Human Cloning\",2 Mask Language Modeling \u00b6 Info input sentence with mask, can be multiple target of each mask should be separate by blank Format: input sentence with [MASK] [MASK],target_token target_token Example : \"how did i [MASK] [MASK]\",\"get here\" Sequence Tagging \u00b6 Info input sentence with blank between each word target label separate with blank, should be one to one to the input Format: input sentence,tag tag Example : \"welcome to New York,O O B_place B_place\"","title":"Tasks"},{"location":"tasks/#task-format","text":"","title":"Task format"},{"location":"tasks/#classification","text":"Info","title":"Classification"},{"location":"tasks/#multi-class-classification","text":"Format: input sentence,label Example: Calotropis procera (ushaar) keratitis.,Not-Related","title":"multi-class classification:"},{"location":"tasks/#multi-label-classification","text":"use /// to separate each label. Format: input sentence,label1///label2 Example : We report two cases of pseudoporphyria caused by naproxen and oxaprozin.,Related///METHODS","title":"multi-label classification"},{"location":"tasks/#text-generation","text":"Info Format: input sentence, target sentence Example : Peter was a truck driver . He was running a little behind on schedule . Peter decided to run past the weigh station . He was stopped by a cop .,\"Peter ended up running late and getting a fine .\"","title":"Text Generation"},{"location":"tasks/#extractive-question-answering","text":"Info Format: input sentence with question, answer start position, answer end position Example : Beyonc\u00e9 announced a hiatus from her music ... <s> Who suggested the hiatus for Beyonc\u00e9?, 74,84","title":"Extractive Question Answering"},{"location":"tasks/#multiple-choice-question-answering","text":"Info Input passage should include all available, each choice must start with a mask token each choice must start with a mask token choice id will be start from 0 Format: input passage [MASK]choiceA [MASK]choiceB, 1 Example : \"I 'm sure many of you have seen Star Wars ... </s> What is the best title of the passage ? [MASK] What Is Human Cloning [MASK] How Does Human Cloning Happen [MASK] Human Cloning Is Wrong [MASK] Discussion On Human Cloning\",2","title":"Multiple-Choice Question Answering"},{"location":"tasks/#mask-language-modeling","text":"Info input sentence with mask, can be multiple target of each mask should be separate by blank Format: input sentence with [MASK] [MASK],target_token target_token Example : \"how did i [MASK] [MASK]\",\"get here\"","title":"Mask Language Modeling"},{"location":"tasks/#sequence-tagging","text":"Info input sentence with blank between each word target label separate with blank, should be one to one to the input Format: input sentence,tag tag Example : \"welcome to New York,O O B_place B_place\"","title":"Sequence Tagging"}]}